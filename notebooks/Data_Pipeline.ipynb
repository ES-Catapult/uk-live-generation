{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Generation Map: BRMS API Calls and Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from ElexonDataPortal import api\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import pipeline_fns as plfns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osdp_folder = os.environ.get(\"OSDP\")\n",
    "# osdp_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder contains your local directory\n",
    "(\n",
    "    location,\n",
    "    location_BMRS,\n",
    "    location_BMRS_PHYBMDATA,\n",
    "    location_BMRS_B1610,\n",
    "    location_BMRS_Final,\n",
    ") = plfns.create_folder_structure(osdp_folder=osdp_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Diff Querying / Change Data Capture (CDC)\n",
    "For both the B1610 data and the PHYBMDATA we want to check if these datasets already exist in the \"OSDP\" directory, and create them if not. <br> <br>\n",
    "We then want to check for the difference since the pipeline was last run as this will be more efficient than requesting all the historic and BM data each time the pipeline is run. <br><br>\n",
    "In order to achieve this, the script first checks for updates to the historic generation by BMU (B1610 report), i.e. whether new B1610 data is available since the pipeline was last run. NB, this report only updates once daily for one entire day. If the B1610 data hasn't been updated for longer than the \"num_days\" variable, then the function will automatically cause the  \"get_setup_B1610_data\" function to run to create a new dataset. <br><br>\n",
    "Once the B1610 data has been updated, the script then checks for updates to the Balancing Mechanism Physical data: it removes any data that has now been replaced with historic data, then proceeds to query for new physical data. The period queried will be the first period since the physical data was last queried until the end of the current day. NB, physical data is updated half-hourly. Hence, this script should eventually run every 30 min.<br><br>\n",
    "At the end, the updated dataframes overwrite the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B1610 = plfns.setup_update_B1610_data(location_BMRS_B1610=location_BMRS_B1610, num_days=14, hist_days=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM_start_date = pd.to_datetime(df_B1610[\"settlementDate\"].max() + timedelta(days=1)).replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PHYBMDATA = plfns.setup_update_PHYBM_data(\n",
    "    BM_start_date=BM_start_date, location_BMRS_PHYBMDATA=location_BMRS_PHYBMDATA\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the BM data to follow a similar patterns as the historic data\n",
    "Next, the balancing mechanism data should be filtered and transformed so that it follows a similar pattern as the B1610 data. <br> <br>\n",
    "Abbreviations (https://www.bmreports.com/bmrs/?q=help/glossary): <br>\n",
    "* **FPN**: Final Physical Notification - \"A Physical Notification is the best estimate of the level of generation or demand that a participant in the BM expects a BM Unit to export or import, respectively, in a Settlement Period.\"\n",
    "* **BOAL(F)**: Bid Offer Acceptance Level - subsequent \"last minute\" changes to this notified generation, e.g. due to curtailment or due to balancing demands. \"A Bid-Offer Acceptance is a formalised representation of the purchase and/or sale of Offers and/or Bids (see Bid-Offer Data below) by the System Operator in its operation of the Balancing Mechanism.\"\n",
    "* **MEL**: Maximum Export Level - It is the maximum power export level of a particular BM Unit at a particular time. It is submitted as a series of point MW values and associated times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpn, df_mel, df_boal = plfns.filter_and_rename_physical_Data(df_PHYBMDATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The half-hourly or sub-half-hourly data is resampled to minutely resolution so that actions that happen at different times during each half-hour period can be joined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boal_long = plfns.convert_physical_data_to_long(df_boal)\n",
    "unit_boal_resolved = plfns.resolve_applied_bid_offer_level(df_boal_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpn_long = plfns.convert_physical_data_to_long(df_fpn)\n",
    "unit_fpn_resolved = plfns.resolve_FPN_MEL_level(df_fpn_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mel_long = plfns.convert_physical_data_to_long(df_mel)\n",
    "unit_mel_resolved = plfns.resolve_FPN_MEL_level(df_mel_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After resampling the data to minutely resolution (Time), join the FPN, BOAL and MEL data.\n",
    "\n",
    "df_fpn_boal = pd.merge(\n",
    "    unit_fpn_resolved, unit_boal_resolved, how=\"outer\", on=[\"Time\", \"bmUnitID\"], suffixes=[\"_fpn\", \"_boal\"]\n",
    ")\n",
    "\n",
    "df_fpn_mel_boal = pd.merge(df_fpn_boal, unit_mel_resolved, how=\"outer\", on=[\"Time\", \"bmUnitID\"]).rename(\n",
    "    columns={\"Level\": \"Level_mel\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fpn_mel_boal[\"quantity\"] = df_fpn_mel_boal[\"Level_boal\"].fillna(\n",
    "    df_fpn_mel_boal[\"Level_fpn\"], inplace=False\n",
    ")  # If a BOAL value exists, use it. Otherwise, retain the FPN value (which will always exist).\n",
    "df_fpn_mel_boal[\"quantity\"] = np.where(\n",
    "    df_fpn_mel_boal[\"quantity\"] > df_fpn_mel_boal[\"Level_mel\"],\n",
    "    df_fpn_mel_boal[\"Level_mel\"],\n",
    "    df_fpn_mel_boal[\"quantity\"],\n",
    ")  # If the MEL is lower than the BOAL or FPN value, cap the generation at the level of the MEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate back up to the settlement period (SP) level and calculate the mean generation during each SP\n",
    "df_fpn_mel_boal[\"settlementPeriod_fpn\"] = df_fpn_mel_boal[\"settlementPeriod_fpn\"].astype(str)\n",
    "df_fpn_mel_boal_agg = (\n",
    "    df_fpn_mel_boal.groupby([\"local_datetime_fpn\", \"settlementDate\", \"settlementPeriod\", \"bmUnitID\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "df_fpn_mel_boal_agg = df_fpn_mel_boal_agg.rename(columns={\"local_datetime_fpn\": \"local_datetime\"})\n",
    "df_fpn_mel_boal_agg = df_fpn_mel_boal_agg[\n",
    "    [\"local_datetime\", \"settlementDate\", \"settlementPeriod\", \"bmUnitID\", \"quantity\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B1610[\"quantity\"] = df_B1610[\"quantity\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation = pd.concat((df_B1610, df_fpn_mel_boal_agg), axis=0)\n",
    "df_generation = df_generation[\n",
    "    df_generation[\"quantity\"] > 0\n",
    "].copy()  # Filter out BM data with a negative value (not a generator) or a value of 0 (B1610 only has positive values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the BMRS data with the Power Station Dictionary Names and Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psd_merged = pd.read_csv(os.path.join(location, \"merged_psd.csv\"), header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation = df_generation.merge(df_psd_merged, how=\"left\", left_on=\"bmUnitID\", right_on=\"sett_bmuID\")\n",
    "df_generation = df_generation[\n",
    "    [\n",
    "        \"local_datetime\",\n",
    "        \"settlementDate\",\n",
    "        \"settlementPeriod\",\n",
    "        \"bmUnitID\",\n",
    "        \"quantity\",\n",
    "        \"dictionary_id\",\n",
    "        \"common_name\",\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"fuel\",\n",
    "    ]\n",
    "]\n",
    "df_generation = df_generation.rename(\n",
    "    columns={\n",
    "        \"local_datetime\": \"localDateTime\",\n",
    "        \"bmUnitID\": \"BMUnitID\",\n",
    "        \"dictionary_id\": \"dictionaryID\",\n",
    "        \"common_name\": \"commonName\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create default values for dashboard\n",
    "df_generation[\"dictionaryID\"] = np.where(df_generation[\"dictionaryID\"].isnull(), 99999, df_generation[\"dictionaryID\"])\n",
    "df_generation[\"commonName\"] = np.where(\n",
    "    df_generation[\"commonName\"].isnull(), \"Unknown Name/Location\", df_generation[\"commonName\"]\n",
    ")\n",
    "df_generation[\"longitude\"] = np.where(df_generation[\"longitude\"].isnull(), -2.547855, df_generation[\"longitude\"])\n",
    "df_generation[\"latitude\"] = np.where(df_generation[\"latitude\"].isnull(), 54.00366, df_generation[\"latitude\"])\n",
    "df_generation[\"fuel\"] = np.where(df_generation[\"fuel\"].isnull(), \"Unknown Fuel\", df_generation[\"fuel\"])\n",
    "\n",
    "\n",
    "# Split data into renewable/non-renewable\n",
    "df_generation[\"lowCarbonGeneration\"] = np.where(\n",
    "    df_generation[\"fuel\"].isin([\"BIOMASS\", \"NPSHYD\", \"NUCLEAR\", \"PS\", \"WIND\", \"Wind\"]),\n",
    "    \"Low Carbon Generation\",\n",
    "    \"Carbon Intensive Generation\",\n",
    ")\n",
    "df_generation[\"renewableGeneration\"] = np.where(\n",
    "    df_generation[\"fuel\"].isin([\"BIOMASS\", \"NPSHYD\", \"PS\", \"WIND\", \"Wind\"]),\n",
    "    \"Renewable Generation\",\n",
    "    \"Non-Renewable Generation\",\n",
    ")\n",
    "\n",
    "# Give the Fuel Types a more friendly name\n",
    "fuel_type_friendly = {\n",
    "    \"BIOMASS\": \"Biomass\",\n",
    "    \"CCGT\": \"Combined-cycle Gas Turbine\",\n",
    "    \"COAL\": \"Coal\",\n",
    "    \"OCGT\": \"Open-cycle Gas Turbine\",\n",
    "    \"NPSHYD\": \"Other Hydro\",\n",
    "    \"NUCLEAR\": \"Nuclear\",\n",
    "    \"PS\": \"Pumped Storage Hydro\",\n",
    "    \"WIND\": \"Wind\",\n",
    "    \"Wind\": \"Wind\",\n",
    "}\n",
    "\n",
    "df_generation[\"fuel\"] = df_generation[\"fuel\"].replace(to_replace=fuel_type_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation.to_csv(os.path.join(location_BMRS_Final, \"Generation_Combined.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "os_data_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "330e47966bd248890b7f6cb1b4c1f2af56f7d2fe136ab68068e8a59c999dca59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
