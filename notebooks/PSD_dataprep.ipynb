{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Station Dictionary (PSD) Data Prep <br>\n",
    "This notebook extracts the latest data from the PSD, splits out the differnet sett_bmu_ids and joins the power stations names and locations. <br>\n",
    "It should be run first, before the pipeline. However, it can be run less frequently than the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import pipeline_fns as plfns\n",
    "\n",
    "osdp_folder = os.environ.get(\"OSDP\")\n",
    "osdp_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which folder contains your local directory\n",
    "(\n",
    "    location,\n",
    "    location_BMRS,\n",
    "    location_BMRS_PHYBMDATA,\n",
    "    location_BMRS_B1610,\n",
    "    location_BMRS_Final,\n",
    ") = plfns.create_folder_structure(osdp_folder=osdp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the different datasets from the PSD repo\n",
    "url_ids = \"https://raw.githubusercontent.com/OSUKED/Power-Station-Dictionary/shiro/data/dictionary/ids.csv\"\n",
    "url_locations = \"https://raw.githubusercontent.com/OSUKED/Power-Station-Dictionary/shiro/data/attribute_sources/plant-locations/plant-locations.csv\"\n",
    "url_common_names = \"https://raw.githubusercontent.com/OSUKED/Power-Station-Dictionary/shiro/data/attribute_sources/common-names/common-names.csv\"\n",
    "fuel_types_psd = \"https://raw.githubusercontent.com/OSUKED/Power-Station-Dictionary/shiro/data/attribute_sources/bmu-fuel-types/fuel_types.csv\"\n",
    "fuel_types_elexon = \"https://www.bmreports.com/bmrs/cloud_doc/BMUFuelType.xls\"\n",
    "\n",
    "df_ids = pd.read_csv(url_ids, usecols=[\"dictionary_id\", \"sett_bmu_id\", \"ngc_bmu_id\"])\n",
    "df_ids = df_ids[df_ids[\"ngc_bmu_id\"].notna()]  # Drop any older power stations that don't have a Settlement BMU ID\n",
    "df_locations = pd.read_csv(url_locations)\n",
    "df_common_names = pd.read_csv(url_common_names)\n",
    "df_fuel_types_psd = pd.read_csv(fuel_types_psd)\n",
    "\n",
    "# For the fuel types which are an Excel file on the web\n",
    "resp = requests.get(fuel_types_elexon)\n",
    "with open(os.path.join(location, \"BMUFuelType.xls\"), \"wb\") as output:\n",
    "    output.write(resp.content)\n",
    "df_fuel_types_elexon = pd.read_excel(\"../data/BMUFuelType.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the IDs dataset so that each of the Settlement BMU IDs becomes its own row\n",
    "df_ngc_ids_long = (\n",
    "    pd.DataFrame(df_ids[\"ngc_bmu_id\"].str.split(\",\").tolist(), index=df_ids[\"dictionary_id\"])\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .drop(columns=\"level_1\")\n",
    "    .rename(columns={0: \"ngc_bmuID\"})\n",
    ")\n",
    "df_ngc_ids_long[\"ngc_bmuID\"] = df_ngc_ids_long[\"ngc_bmuID\"].str.strip()\n",
    "\n",
    "df_sett_ids_long = (\n",
    "    pd.DataFrame(df_ids[\"sett_bmu_id\"].str.split(\",\").tolist(), index=df_ids[\"dictionary_id\"])\n",
    "    .stack()\n",
    "    .reset_index()\n",
    "    .drop(columns=\"level_1\")\n",
    "    .rename(columns={0: \"sett_bmuID\"})\n",
    ")\n",
    "df_sett_ids_long[\"sett_bmuID\"] = df_sett_ids_long[\"sett_bmuID\"].str.strip()\n",
    "df_sett_ids_long[\"sett_ngc_bmu_matching_ID\"] = df_sett_ids_long[\"sett_bmuID\"].str.slice(start=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the exploded IDs dataset with the common names, locations and psd fuel types\n",
    "df_psd_merged = df_sett_ids_long.merge(df_common_names, how=\"left\", on=\"dictionary_id\").merge(\n",
    "    df_locations, how=\"left\", on=\"dictionary_id\"\n",
    ")\n",
    "df_psd_merged = df_psd_merged.merge(\n",
    "    df_fuel_types_psd, how=\"left\", left_on=\"sett_ngc_bmu_matching_ID\", right_on=\"ngc_bmu_id\"\n",
    ")\n",
    "\n",
    "# Merge the fuel types based on the BMU ID and the SETT_BMU_ID\n",
    "df_psd_merged = df_psd_merged.merge(\n",
    "    df_fuel_types_elexon[[\"SETT_BMU_ID\", \"FUEL TYPE\"]], how=\"left\", left_on=\"sett_bmuID\", right_on=\"SETT_BMU_ID\"\n",
    ")\n",
    "\n",
    "# Set the final fuel type from the two datasets\n",
    "df_psd_merged[\"fuel\"] = np.where(\n",
    "    df_psd_merged[\"FUEL TYPE\"].isnull(), df_psd_merged[\"fuel_type\"], df_psd_merged[\"FUEL TYPE\"]\n",
    ")\n",
    "df_psd_merged = df_psd_merged.drop(\n",
    "    columns=[\"sett_ngc_bmu_matching_ID\", \"fuel_type\", \"comments\", \"SETT_BMU_ID\", \"FUEL TYPE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the merged dataset to the repo\n",
    "df_psd_merged.to_csv(os.path.join(location, \"merged_psd.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "os_data_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "330e47966bd248890b7f6cb1b4c1f2af56f7d2fe136ab68068e8a59c999dca59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
